========================================MySql to Hive==================================================================


ak@ak:~$ sqoop-import --connect jdbc:mysql://localhost/sqoopdb?useSSL=false -username ak  -password ak  --table policy  -create-hive-table  -hive-table ofsa.policysqoop   -hive-import --fields-terminated-by  ',' -m 1; 
Warning: /home/ak/sqoop-1.4.7.bin__hadoop-2.6.0/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /home/ak/sqoop-1.4.7.bin__hadoop-2.6.0/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /home/ak/sqoop-1.4.7.bin__hadoop-2.6.0/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /home/ak/sqoop-1.4.7.bin__hadoop-2.6.0/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/11/09 14:59:40 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/11/09 14:59:40 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/11/09 14:59:41 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
21/11/09 14:59:41 INFO tool.CodeGenTool: Beginning code generation
Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.
21/11/09 14:59:41 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `policy` AS t LIMIT 1
21/11/09 14:59:41 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `policy` AS t LIMIT 1
21/11/09 14:59:41 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /home/ak/hadoop-2.10.1
Note: /tmp/sqoop-ak/compile/811000136dfbb653e035b75f504bf1da/policy.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
21/11/09 14:59:43 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-ak/compile/811000136dfbb653e035b75f504bf1da/policy.jar
21/11/09 14:59:43 WARN manager.MySQLManager: It looks like you are importing from mysql.
21/11/09 14:59:43 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
21/11/09 14:59:43 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
21/11/09 14:59:43 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
21/11/09 14:59:43 INFO mapreduce.ImportJobBase: Beginning import of policy
21/11/09 14:59:43 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
21/11/09 14:59:44 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
21/11/09 14:59:44 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
21/11/09 14:59:48 INFO db.DBInputFormat: Using read commited transaction isolation
21/11/09 14:59:49 INFO mapreduce.JobSubmitter: number of splits:1
21/11/09 14:59:49 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1636354167280_0014
21/11/09 14:59:49 INFO conf.Configuration: resource-types.xml not found
21/11/09 14:59:49 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
21/11/09 14:59:49 INFO resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
21/11/09 14:59:49 INFO resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
21/11/09 14:59:49 INFO impl.YarnClientImpl: Submitted application application_1636354167280_0014
21/11/09 14:59:49 INFO mapreduce.Job: The url to track the job: http://ak:8088/proxy/application_1636354167280_0014/
21/11/09 14:59:49 INFO mapreduce.Job: Running job: job_1636354167280_0014
21/11/09 14:59:57 INFO mapreduce.Job: Job job_1636354167280_0014 running in uber mode : false
21/11/09 14:59:57 INFO mapreduce.Job:  map 0% reduce 0%
21/11/09 15:00:06 INFO mapreduce.Job:  map 100% reduce 0%
21/11/09 15:00:06 INFO mapreduce.Job: Job job_1636354167280_0014 completed successfully
21/11/09 15:00:06 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=217325
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=87
		HDFS: Number of bytes written=62
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Other local map tasks=1
		Total time spent by all maps in occupied slots (ms)=6154
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=6154
		Total vcore-milliseconds taken by all map tasks=6154
		Total megabyte-milliseconds taken by all map tasks=6301696
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Input split bytes=87
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=184
		CPU time spent (ms)=1640
		Physical memory (bytes) snapshot=205991936
		Virtual memory (bytes) snapshot=1908228096
		Total committed heap usage (bytes)=102236160
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=62
21/11/09 15:00:06 INFO mapreduce.ImportJobBase: Transferred 62 bytes in 22.4155 seconds (2.7659 bytes/sec)
21/11/09 15:00:06 INFO mapreduce.ImportJobBase: Retrieved 3 records.
21/11/09 15:00:06 INFO mapreduce.ImportJobBase: Publishing Hive/Hcat import job data to Listeners for table policy
21/11/09 15:00:07 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `policy` AS t LIMIT 1
21/11/09 15:00:07 INFO hive.HiveImport: Loading uploaded data into Hive
21/11/09 15:00:07 INFO conf.HiveConf: Found configuration file file:/home/ak/apache-hive-3.1.2-bin/conf/hive-site.xml
21/11/09 15:00:08 INFO hive.HiveImport: SLF4J: Class path contains multiple SLF4J bindings.
21/11/09 15:00:08 INFO hive.HiveImport: SLF4J: Found binding in [jar:file:/home/ak/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
21/11/09 15:00:08 INFO hive.HiveImport: SLF4J: Found binding in [jar:file:/home/ak/hadoop-2.10.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
21/11/09 15:00:08 INFO hive.HiveImport: SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
21/11/09 15:00:08 INFO hive.HiveImport: SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
21/11/09 15:00:13 INFO hive.HiveImport: Hive Session ID = 5e3f2795-2ed5-41c0-b308-e9f1ff5e5a62
21/11/09 15:00:13 INFO hive.HiveImport: 
21/11/09 15:00:13 INFO hive.HiveImport: Logging initialized using configuration in jar:file:/home/ak/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
21/11/09 15:00:21 INFO hive.HiveImport: Hive Session ID = e000217c-6f61-414e-bc94-d0415c3f8f3d
21/11/09 15:00:24 INFO hive.HiveImport: OK
21/11/09 15:00:24 INFO hive.HiveImport: Time taken: 2.391 seconds
21/11/09 15:00:25 INFO hive.HiveImport: Loading data to table ofsa.policysqoop
21/11/09 15:00:25 INFO hive.HiveImport: OK
21/11/09 15:00:25 INFO hive.HiveImport: Time taken: 1.304 seconds
21/11/09 15:00:26 INFO hive.HiveImport: Hive import complete.
21/11/09 15:00:26 INFO hive.HiveImport: Export directory is contains the _SUCCESS file only, removing the directory.


========================================checking in hive==================================================================


hive> show tables;
OK
parquet_file
patient
patorc_file
policysqoop
Time taken: 0.139 seconds, Fetched: 4 row(s)
hive> select * from policysqoop;
OK
3001	Anand	50000	30
3002	Gautam	50000	10
3003	Sairam	30000	20
3004	Ram	5000	60
3005	Anita	5000	15
Time taken: 0.217 seconds, Fetched: 5 row(s)



========================================Inserting values into policy================================================


mysql> select * from policy;
+-----------+---------------+-------------+----------------+
| policy_id | policy_holder | sum_insured | terms_in_years |
+-----------+---------------+-------------+----------------+
|      3001 | Anand         |       50000 |             30 |
|      3002 | Gautam        |       50000 |             10 |
|      3003 | Sairam        |       30000 |             20 |
|      3004 | Ram           |        5000 |             60 |
|      3005 | Anita         |        5000 |             15 |
+-----------+---------------+-------------+----------------+
5 rows in set (0.00 sec)

mysql> insert into policy values(3006,'Monish',3000,20);
Query OK, 1 row affected (0.01 sec)

mysql> insert into policy values(3007,'Vicky',5000,25);
Query OK, 1 row affected (0.00 sec)

mysql> select * from policy;
+-----------+---------------+-------------+----------------+
| policy_id | policy_holder | sum_insured | terms_in_years |
+-----------+---------------+-------------+----------------+
|      3001 | Anand         |       50000 |             30 |
|      3002 | Gautam        |       50000 |             10 |
|      3003 | Sairam        |       30000 |             20 |
|      3004 | Ram           |        5000 |             60 |
|      3005 | Anita         |        5000 |             15 |
|      3006 | Monish        |        3000 |             20 |
|      3007 | Vicky         |        5000 |             25 |
+-----------+---------------+-------------+----------------+
7 rows in set (0.00 sec)


========================================Incremental import ================================================


ak@ak:~$ sqoop-import  --connect jdbc:mysql://localhost/sqoopdb?useSSL=false -username ak  -password ak  --table policy  --incremental  append --check-column policy_id -last-value 3005 -m 1
Warning: /home/ak/sqoop-1.4.7.bin__hadoop-2.6.0/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /home/ak/sqoop-1.4.7.bin__hadoop-2.6.0/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /home/ak/sqoop-1.4.7.bin__hadoop-2.6.0/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /home/ak/sqoop-1.4.7.bin__hadoop-2.6.0/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/11/09 15:57:52 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/11/09 15:57:52 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/11/09 15:57:52 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
21/11/09 15:57:52 INFO tool.CodeGenTool: Beginning code generation
Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.
21/11/09 15:57:52 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `policy` AS t LIMIT 1
21/11/09 15:57:52 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `policy` AS t LIMIT 1
21/11/09 15:57:52 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /home/ak/hadoop-2.10.1
Note: /tmp/sqoop-ak/compile/f524d7131a8271b2d4808baed8f76947/policy.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
21/11/09 15:57:54 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-ak/compile/f524d7131a8271b2d4808baed8f76947/policy.jar
21/11/09 15:57:54 INFO tool.ImportTool: Maximal id query for free form incremental import: SELECT MAX(`policy_id`) FROM `policy`
21/11/09 15:57:54 INFO tool.ImportTool: Incremental import based on column `policy_id`
21/11/09 15:57:54 INFO tool.ImportTool: Lower bound value: 3005
21/11/09 15:57:54 INFO tool.ImportTool: Upper bound value: 3007
21/11/09 15:57:54 WARN manager.MySQLManager: It looks like you are importing from mysql.
21/11/09 15:57:54 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
21/11/09 15:57:54 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
21/11/09 15:57:54 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
21/11/09 15:57:54 INFO mapreduce.ImportJobBase: Beginning import of policy
21/11/09 15:57:54 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
21/11/09 15:57:54 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
21/11/09 15:57:55 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
21/11/09 15:57:58 INFO db.DBInputFormat: Using read commited transaction isolation
21/11/09 15:57:59 INFO mapreduce.JobSubmitter: number of splits:1
21/11/09 15:57:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1636354167280_0019
21/11/09 15:57:59 INFO conf.Configuration: resource-types.xml not found
21/11/09 15:57:59 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
21/11/09 15:57:59 INFO resource.ResourceUtils: Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
21/11/09 15:57:59 INFO resource.ResourceUtils: Adding resource type - name = vcores, units = , type = COUNTABLE
21/11/09 15:57:59 INFO impl.YarnClientImpl: Submitted application application_1636354167280_0019
21/11/09 15:57:59 INFO mapreduce.Job: The url to track the job: http://ak:8088/proxy/application_1636354167280_0019/
21/11/09 15:57:59 INFO mapreduce.Job: Running job: job_1636354167280_0019
21/11/09 15:58:05 INFO mapreduce.Job: Job job_1636354167280_0019 running in uber mode : false
21/11/09 15:58:05 INFO mapreduce.Job:  map 0% reduce 0%
21/11/09 15:58:10 INFO mapreduce.Job:  map 100% reduce 0%
21/11/09 15:58:10 INFO mapreduce.Job: Job job_1636354167280_0019 completed successfully
21/11/09 15:58:11 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=217570
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=87
		HDFS: Number of bytes written=39
		HDFS: Number of read operations=4
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Other local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2577
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=2577
		Total vcore-milliseconds taken by all map tasks=2577
		Total megabyte-milliseconds taken by all map tasks=2638848
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Input split bytes=87
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=60
		CPU time spent (ms)=670
		Physical memory (bytes) snapshot=207470592
		Virtual memory (bytes) snapshot=1908670464
		Total committed heap usage (bytes)=103809024
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=39
21/11/09 15:58:11 INFO mapreduce.ImportJobBase: Transferred 39 bytes in 16.1612 seconds (2.4132 bytes/sec)
21/11/09 15:58:11 INFO mapreduce.ImportJobBase: Retrieved 2 records.
21/11/09 15:58:11 INFO util.AppendUtils: Creating missing output directory - policy
21/11/09 15:58:11 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
21/11/09 15:58:11 INFO tool.ImportTool:  --incremental append
21/11/09 15:58:11 INFO tool.ImportTool:   --check-column policy_id
21/11/09 15:58:11 INFO tool.ImportTool:   --last-value 3007
21/11/09 15:58:11 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')


ak@ak:~$ hdfs dfs -ls -R  /user/ak
drwxr-xr-x   - ak supergroup          0 2021-11-09 15:58 /user/ak/_sqoop
drwxr-xr-x   - ak supergroup          0 2021-11-08 16:02 /user/ak/day1
-rw-r--r--   1 ak supergroup  450619960 2021-11-08 15:06 /user/ak/day1/hadoop-2.10.1.zip
-rw-r--r--   2 ak supergroup   12064491 2021-11-08 16:02 /user/ak/day1/store.csv
drwxr-xr-x   - ak supergroup          0 2021-11-09 15:58 /user/ak/policy
-rw-r--r--   2 ak supergroup         39 2021-11-09 15:58 /user/ak/policy/part-m-00000
drwxr-xr-x   - ak supergroup          0 2021-10-30 13:38 /user/ak/test
ak@ak:~$ 


======================================== End ================================================





     | 




